# -*- coding: utf-8 -*-
"""Trading_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15jGhL53MdT7Uk19zOuqgJkQYMPPcaRRq

# Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math
from datetime import date
import missingno as msno
from scipy.stats import norm
from scipy.signal import find_peaks
from scipy.signal import argrelextrema

pd.set_option('display.max_columns', 500)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.width', 10000)
pd.set_option("display.float_format", lambda x: f"{x:.10f}")

from sklearn.utils import resample
from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve
from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV
from matplotlib import rc,rcParams
import itertools
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder

from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN
from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

import warnings
warnings.filterwarnings('ignore')

"""# Relative Strength Index (RSI)"""

def calculate_rsi(price_data, window=14, price_col='close'):
    """
    Correct RSI calculation.
    """
    delta = price_data[price_col].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = gain.rolling(window=window).mean()
    avg_loss = loss.rolling(window=window).mean()

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    return rsi

"""# Categorical RSI  """

def categorize_rsi(rsi_series):
    """
    Categorize RSI values into bins:
    0-30, 30-50, 50-70, 70-100

    Args:
        rsi_series (pd.Series): RSI values

    Returns:
        pd.Series: Categorical RSI bins
    """
    bins = [0, 30, 50, 70, 100]
    labels = ['oversold', 'below_avg', 'above_avg', 'overbought']
    return pd.cut(rsi_series, bins=bins, labels=labels, include_lowest=True)

"""# Average True Range (ATR)"""

def calculate_atr(price_data, window=14):
    """
    Calculate ATR (Average True Range) using Wilder's RMA.

    Args:
        price_data (pd.DataFrame): DataFrame containing columns 'high', 'low', 'close'
        window (int): Lookback period (default: 14)

    Returns:
        pd.Series: ATR values
    """
    high = price_data['high']
    low = price_data['low']
    close = price_data['close']

    # Calculate True Range (TR)
    previous_close = close.shift(1)
    tr1 = high - low
    tr2 = abs(high - previous_close)
    tr3 = abs(low - previous_close)
    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

    # ATR = RMA of True Range
    atr = true_range.ewm(alpha=1/window, adjust=False).mean()

    return atr

"""# Bollinger Bands"""

def calculate_bollinger_bands(price_data, window=20, std_multiplier=2, price_col='close'):
    """
    Calculate Bollinger Bands.

    Args:
        price_data (pd.DataFrame): DataFrame containing OHLC prices
        window (int): Lookback period for SMA (default: 20)
        std_multiplier (float): Standard deviation multiplier (default: 2)
        price_col (str): Column name for price (default: 'close')

    Returns:
        pd.DataFrame: DataFrame with 'bb_middle', 'bb_upper', 'bb_lower' columns
    """
    price = price_data[price_col]

    # Middle Band: SMA
    sma = price.rolling(window=window).mean()

    # Standard Deviation
    std = price.rolling(window=window).std()

    # Upper and Lower Bands
    upper_band = sma + std_multiplier * std
    lower_band = sma - std_multiplier * std

    # Return as DataFrame
    bb = pd.DataFrame({
        'bb_middle': sma,
        'bb_upper': upper_band,
        'bb_lower': lower_band
    })

    return bb

"""# Donchain Channels"""

#USE 20, 50 OR 55

def calculate_donchian_channel(price_data, window=20):
    """
    Calculate Donchian Channel.

    Args:
        price_data (pd.DataFrame): DataFrame with 'high' and 'low' columns
        window (int): Lookback period (default: 20)

    Returns:
        pd.DataFrame: DataFrame with 'dc_upper', 'dc_lower', 'dc_middle'
    """
    upper_band = price_data['high'].rolling(window=window).max()
    lower_band = price_data['low'].rolling(window=window).min()
    middle_band = (upper_band + lower_band) / 2

    dc = pd.DataFrame({
        'dc_upper': upper_band,
        'dc_lower': lower_band,
        'dc_middle': middle_band
    })

    return dc

"""# Simple Moving Average - SMA"""

# USE 13, 50, 100 OR 200

def calculate_sma(price_data, window=50, price_col='close'):
    """
    Calculate Simple Moving Average (SMA).

    Args:
        price_data (pd.DataFrame): DataFrame containing price data
        window (int): Lookback period for SMA (default: 50)
        price_col (str): Column name for price (default: 'close')

    Returns:
        pd.Series: SMA values
    """
    sma = price_data[price_col].rolling(window=window).mean()
    return sma

"""# Trend"""

def determine_sma_trend(price_data, short_window=50, long_window=200, price_col='close'):
    """
    Determine trend based on SMA crossover.

    Args:
        price_data (pd.DataFrame): DataFrame containing price data
        short_window (int): Short SMA period (default: 13)
        long_window (int): Long SMA period (default: 50)
        price_col (str): Column name for price (default: 'close')

    Returns:
        pd.Series: Trend labels ('uptrend' or 'downtrend')
    """
    short_sma = price_data[price_col].rolling(window=short_window).mean()
    long_sma = price_data[price_col].rolling(window=long_window).mean()

    trend = np.where(short_sma > long_sma, 'uptrend', 'downtrend')

    return pd.Series(trend, index=price_data.index)

"""# EMA"""

def calculate_ema(df, window=50, column='close'):
    """
    DataFrame için EMA (Exponential Moving Average) hesaplar

    Parameters:
    df (pd.DataFrame): Fiyat verilerini içeren DataFrame
    window (int): EMA periyodu (varsayılan: 50)
    column (str): Kullanılacak sütun adı (varsayılan: 'close')

    Returns:
    pd.Series: Hesaplanan EMA değerleri
    """

    # Düzgünleştirme faktörü (alpha)
    alpha = 2 / (window + 1)

    # EMA hesaplama - pandas ewm fonksiyonu kullanarak
    ema = df[column].ewm(alpha=alpha, adjust=False).mean()

    return ema

"""# Nadaraya Watson Envelope"""

def calculate_nadaraya_watson_envelope_optimized(df, bandwidth=8.0, multiplier=3.0, source_col='close', window_size=50):# window_size=500 kullanımı da var.
    """
    Nadaraya-Watson Envelope'un repaint olmayan modunu hesaplar.
    Sadece hesaplanan 'nw_lower', 'nw', 'nw_upper' sütunlarını içeren bir DataFrame döndürür.

    Parametreler:
    df (pd.DataFrame): 'close', 'open', 'high', 'low', 'time' sütunlarına sahip DataFrame.
    bandwidth (float): Nadaraya-Watson için bant genişliği (h).
    multiplier (float): Zarfların genişliğini ayarlamak için çarpan.
    source_col (str): Hesaplama için kullanılacak kaynak sütun adı (örn: 'close').
    window_size (int): Nadaraya-Watson ve MAE hesaplamalarında kullanılacak maksimum geçmiş bar sayısı.

    Döndürür:
    pd.DataFrame: 'nw_lower', 'nw', 'nw_upper' sütunlarını içeren yeni bir DataFrame.
                  Bu DataFrame'in indeksleri orijinal df ile aynı olacaktır.
    """

    n_bars = len(df)
    source_data = df[source_col].values # NumPy array'ine dönüştürerek erişimi hızlandır

    # Gaussian kernel fonksiyonu
    def gauss(x, h):
        return np.exp(-(x**2) / (h * h * 2))

    # Ağırlıkları bir kere hesapla
    weights = np.array([gauss(i, bandwidth) for i in range(window_size)])
    weights_sum = np.sum(weights)

    # Sonuçları saklamak için NumPy array'leri oluştur (önceden bellek tahsisi)
    nw_out_arr = np.full(n_bars, np.nan)
    nw_lower_arr = np.full(n_bars, np.nan)
    nw_upper_arr = np.full(n_bars, np.nan)

    # Her bar için hesaplama yap
    for i in range(n_bars):
        if i < window_size - 1:
            continue

        # Nadaraya-Watson çizgisi (nw_out) hesaplaması
        # NumPy dilimleme ve dot product kullanarak hızlandırılmış hesaplama
        # source_data[i - window_size + 1 : i + 1] son 'window_size' kadar veriyi alır
        # weights[::-1] ağırlıkları ters çevirir çünkü en yakın veriye en yüksek ağırlık gelir
        weighted_sum = np.dot(source_data[i - window_size + 1 : i + 1], weights[::-1])

        current_nw_out = weighted_sum / weights_sum
        nw_out_arr[i] = current_nw_out

        # MAE hesaplaması (Artık 'nw_out_arr' değerlerini kullanarak daha doğru bir MAE)
        # Sadece yeterli geçmiş veri olduğunda hesapla
        if i >= window_size -1:
            # Geçmiş src ve nw_out farklarını al
            abs_diffs = np.abs(source_data[i - window_size + 1 : i + 1] - nw_out_arr[i - window_size + 1 : i + 1])
            current_mae = np.mean(abs_diffs) * multiplier # ta.sma'ya benzer

            nw_lower_arr[i] = current_nw_out - current_mae
            nw_upper_arr[i] = current_nw_out + current_mae

    # Sonuçları yeni bir DataFrame olarak döndür
    results_df = pd.DataFrame({
        'nw': nw_out_arr,
        'nw_upper': nw_upper_arr,
        'nw_lower': nw_lower_arr
    }, index=df.index) # Orijinal DataFrame'in indeksini koru

    return results_df

"""# Stochastic"""

def calculate_stochastic(price_data, k_length=50, k_smoothing=21, d_smoothing=8):
    """
    TradingView style Stochastic Oscillator.

    Args:
        price_data (pd.DataFrame): must have 'High', 'Low', 'Close'
        k_length (int): %K Length (lookback)
        k_smoothing (int): %K Smoothing
        d_smoothing (int): %D Smoothing

    Returns:
        pd.DataFrame: 'stoch_k', 'stoch_d'
    """
    low_min = price_data['low'].rolling(window=k_length).min()
    high_max = price_data['high'].rolling(window=k_length).max()

    raw_k = 100 * (price_data['close'] - low_min) / (high_max - low_min)
    stoch_k = raw_k.rolling(window=k_smoothing).mean()
    stoch_d = stoch_k.rolling(window=d_smoothing).mean()

    return pd.DataFrame({
        'stoch_k': stoch_k,
        'stoch_d': stoch_d
    })

"""# Stochastic RSI"""

def rma(series, length):
    """Wilder's RMA: TradingView'deki ta.rma ile birebir."""
    alpha = 1 / length
    rma = series.ewm(alpha=alpha, adjust=False).mean()
    return rma

def calculate_stoch_rsi(
    price_data,
    rsi_length=14,
    stoch_length=14,
    k_smoothing=21,
    d_smoothing=8,
    price_col='close'
):
    """
    TradingView birebir Stoch RSI — RMA tabanlı

    Returns:
        'stoch_rsi_k', 'stoch_rsi_d' (0-100)
    """
    # 1) RSI (RMA tabanlı)
    delta = price_data[price_col].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)

    avg_gain = rma(gain, rsi_length)
    avg_loss = rma(loss, rsi_length)

    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    # 2) Stoch RSI
    rsi_min = rsi.rolling(window=stoch_length).min()
    rsi_max = rsi.rolling(window=stoch_length).max()

    stoch_rsi = 100 * (rsi - rsi_min) / (rsi_max - rsi_min)
    stoch_rsi = stoch_rsi.clip(0, 100)

    # 3) %K ve %D smoothing — RMA tabanlı
    stoch_rsi_k = rma(stoch_rsi, k_smoothing)
    stoch_rsi_d = rma(stoch_rsi_k, d_smoothing)

    return pd.DataFrame({
        'stoch_rsi_k': stoch_rsi_k,
        'stoch_rsi_d': stoch_rsi_d
    })

"""# MACD"""

def calculate_macd(price_data, fast=21, slow=50, signal=9, price_col='close'):
    """
    Calculate MACD and Signal Line.

    Args:
        price_data (pd.DataFrame): must have price_col
        fast (int): Fast EMA period
        slow (int): Slow EMA period
        signal (int): Signal line EMA period

    Returns:
        pd.DataFrame: 'macd_line', 'macd_signal', 'macd_hist'
    """
    ema_fast = price_data[price_col].ewm(span=fast, adjust=False).mean()
    ema_slow = price_data[price_col].ewm(span=slow, adjust=False).mean()

    macd_line = ema_fast - ema_slow
    macd_signal = macd_line.ewm(span=signal, adjust=False).mean()
    macd_hist = macd_line - macd_signal

    return pd.DataFrame({
        'macd_line': macd_line,
        'macd_signal': macd_signal,
        'macd_hist': macd_hist
    })

"""# ADX"""

def add_adx(df, period=14):
    """
    DataFrame'e ADX (Average Directional Index) göstergesini ekler.

    Parametreler:
    df (pd.DataFrame): 'high', 'low' ve 'close' sütunlarını içeren DataFrame.
                       Sütun isimlerinin küçük harf olduğundan emin olun.
    period (int): ADX hesaplaması için kullanılacak periyot (varsayılan 14).

    Döndürür:
    pd.DataFrame: ADX, +DI, -DI ve DX sütunları eklenmiş DataFrame.
    """

    # Gerekli sütunların küçük harf kontrolü ve hata yönetimi
    required_cols = ['high', 'low', 'close']
    if not all(col in df.columns for col in required_cols):
        raise ValueError(f"DataFrame'de '{', '.join(required_cols)}' sütunları bulunmalıdır ve küçük harf olmalıdır.")

    # Geçici çalışma DataFrame'i oluştur (orijinal df'i değiştirmemek için kopyala)
    df_adx = df.copy()

    # --- Yardımcı EMA Hesaplama Fonksiyonu ---
    def _calculate_ema(series, p):
        ema_values = [np.nan] * len(series)
        if len(series) < p:
            return pd.Series(ema_values, index=series.index)

        # İlk EMA değeri için SMA kullanılır
        ema_values[p - 1] = series.iloc[:p].mean()

        alpha = 2 / (p + 1)
        for i in range(p, len(series)):
            ema_values[i] = (series.iloc[i] * alpha) + (ema_values[i-1] * (1 - alpha))

        return pd.Series(ema_values, index=series.index)

    # --- 1. Adım: True Range (TR) Hesapla ---
    # TR = Max[(high - low), abs(high - prev_close), abs(low - prev_close)]
    df_adx['prev_close'] = df_adx['close'].shift(1)
    df_adx['high_low'] = df_adx['high'] - df_adx['low']
    df_adx['high_prev_close'] = abs(df_adx['high'] - df_adx['prev_close'])
    df_adx['low_prev_close'] = abs(df_adx['low'] - df_adx['prev_close'])
    df_adx['tr'] = df_adx[['high_low', 'high_prev_close', 'low_prev_close']].max(axis=1)

    # --- 2. Adım: Directional Movement (+DM ve -DM) Hesapla ---
    df_adx['prev_high'] = df_adx['high'].shift(1)
    df_adx['prev_low'] = df_adx['low'].shift(1)
    df_adx['up_move'] = df_adx['high'] - df_adx['prev_high']
    df_adx['down_move'] = df_adx['prev_low'] - df_adx['low']

    df_adx['+dm'] = np.where(
        (df_adx['up_move'] > df_adx['down_move']) & (df_adx['up_move'] > 0),
        df_adx['up_move'],
        0
    )
    df_adx['-dm'] = np.where(
        (df_adx['down_move'] > df_adx['up_move']) & (df_adx['down_move'] > 0),
        df_adx['down_move'],
        0
    )

    # --- 3. Adım: ATR, +DM ve -DM'nin Üssel Hareketli Ortalamalarını (EMA) Hesapla ---
    df_adx['tr_ema'] = _calculate_ema(df_adx['tr'], period)
    df_adx['+dm_ema'] = _calculate_ema(df_adx['+dm'], period)
    df_adx['-dm_ema'] = _calculate_ema(df_adx['-dm'], period)

    # --- 4. Adım: Yönsel İndeksler (DI) Hesapla ---
    df_adx['+di'] = (df_adx['+dm_ema'] / df_adx['tr_ema']) * 100
    df_adx['-di'] = (df_adx['-dm_ema'] / df_adx['tr_ema']) * 100

    # Sonsuzlukları ve sıfıra bölme hatalarını yönet
    df_adx['+di'].replace([np.inf, -np.inf], np.nan, inplace=True)
    df_adx['-di'].replace([np.inf, -np.inf], np.nan, inplace=True)
    df_adx.loc[df_adx['tr_ema'] == 0, ['+di', '-di']] = np.nan

    # --- 5. Adım: Yönsel Hareket İndeksi (DX) Hesapla ---
    df_adx['dx'] = (abs(df_adx['+di'] - df_adx['-di']) / (df_adx['+di'] + df_adx['-di'])) * 100
    df_adx['dx'].replace([np.inf, -np.inf], np.nan, inplace=True)
    df_adx.loc[(df_adx['+di'] + df_adx['-di']) == 0, 'dx'] = np.nan

    # --- 6. Adım: ADX Hesapla (DX'in EMA'sı) ---
    df_adx['adx'] = _calculate_ema(df_adx['dx'], period)

    # İstenirse ara hesaplama sütunlarını temizle
    # df_adx.drop(columns=['prev_close', 'high_low', 'high_prev_close', 'low_prev_close',
    #                      'prev_high', 'prev_low', 'up_move', 'down_move',
    #                      'tr', '+dm', '-dm', 'tr_ema', '+dm_ema', '-dm_ema', 'dx'],
    #                     errors='ignore', inplace=True)

    return df_adx

"""# OBV"""

def add_obv(df):
    """
    DataFrame'e OBV (On-Balance Volume) göstergesini ekler.

    Parametreler:
    df (pd.DataFrame): 'close' ve 'volume' sütunlarını içeren DataFrame.
                       Sütun isimlerinin küçük harf olduğundan emin olun.

    Döndürür:
    pd.DataFrame: 'obv' sütunu eklenmiş DataFrame.
    """

    # Gerekli sütunların küçük harf kontrolü ve hata yönetimi
    required_cols = ['close', 'volume']
    if not all(col in df.columns for col in required_cols):
        raise ValueError(f"DataFrame'de '{', '.join(required_cols)}' sütunları bulunmalıdır ve küçük harf olmalıdır.")

    # Geçici çalışma DataFrame'i oluştur (orijinal df'i değiştirmemek için kopyala)
    df_obv = df.copy()

    # OBV sütununu başlat, ilk değeri 0 veya ilk barın hacmi olabilir.
    # Genellikle ilk barın hacmi alınır.
    df_obv['obv'] = 0.0 # float olarak başlat

    # İlk OBV değeri: İlk kapanış ve hacim verisi kullanılarak belirlenir
    # df_obv['obv'].iloc[0] = df_obv['volume'].iloc[0] # Bu da bir yaklaşım
    # Ancak sıfırdan başlamak da yaygındır ve sonraki hesaplamayı etkilemez

    # Döngü ile OBV'yi hesapla
    for i in range(1, len(df_obv)):
        # Kapanış fiyatlarının önceki kapanışa göre karşılaştırılması
        if df_obv['close'].iloc[i] > df_obv['close'].iloc[i-1]:
            # Fiyat yükseldi, hacmi ekle
            df_obv['obv'].iloc[i] = df_obv['obv'].iloc[i-1] + df_obv['volume'].iloc[i]
        elif df_obv['close'].iloc[i] < df_obv['close'].iloc[i-1]:
            # Fiyat düştü, hacmi çıkar
            df_obv['obv'].iloc[i] = df_obv['obv'].iloc[i-1] - df_obv['volume'].iloc[i]
        else:
            # Fiyat değişmedi, OBV aynı kalır
            df_obv['obv'].iloc[i] = df_obv['obv'].iloc[i-1]

    return df_obv

"""# Candle"""

def candle(df):
    if df['close'] > df['open']:
        return'green'
    else:
        return 'red'

def classify_strength(row):
    if row['close'] > row['open']:
        if row['candle_strength'] > 1.1:
            return 'strong_bullish'
        elif row['candle_strength'] > 0.7:
            return 'medium_bullish'
        else:
            return 'weak_bullish'
    else:
        if row['candle_strength'] > 1.1:
            return 'strong_bearish'
        elif row['candle_strength'] > 0.7:
            return 'medium_bearish'
        else:
            return 'weak_bearish'

"""# Zigzag"""

def zigzag(prices, pct=2):
    last_pivot = prices[0]
    pivots = [np.nan] * len(prices)
    directions = [0] * len(prices)
    direction = 0  # 1: up, -1: down

    for i in range(1, len(prices)):
        change = (prices[i] - last_pivot) / last_pivot * 100

        if direction >= 0 and change <= -pct:  # düşüş pivotu (tepe)
            direction = -1
            pivots[i] = prices[i]
            directions[i] = -1
            last_pivot = prices[i]
        elif direction <= 0 and change >= pct:  # yükseliş pivotu (dip)
            direction = 1
            pivots[i] = prices[i]
            directions[i] = 1
            last_pivot = prices[i]
    return pivots, directions

"""# Zigzag-ATR"""

def atr_zigzag(df, atr_col="atr", close_col="close"):
    """
    ATR bazlı zigzag (strict mode).
    Yeni pivot, ancak ters yönde 1 ATR hareket olunca kesinleşir.
    """
    closes = df[close_col].values
    atrs = df[atr_col].values

    pivots = [None] * len(df)
    last_pivot = closes[0]
    last_atr = atrs[0]
    last_pivot_idx = 0
    direction = None  # "up" veya "down"

    for i in range(1, len(df)):
        price = closes[i]
        atr = atrs[i]

        if direction is None:
            # henüz yön yok → ilk büyük hareket yönü belirler
            if price >= last_pivot + atr:
                direction = "up"
                last_pivot = closes[last_pivot_idx]
                pivots[last_pivot_idx] = last_pivot
            elif price <= last_pivot - atr:
                direction = "down"
                last_pivot = closes[last_pivot_idx]
                pivots[last_pivot_idx] = last_pivot

        elif direction == "up":
            # fiyat yükseliyor
            if price <= (last_pivot - last_atr):
                # son pivot teyit edildi → bu bir tepeydi
                pivots[last_pivot_idx] = last_pivot
                direction = "down"
                last_pivot = price
                last_pivot_idx = i
                last_atr = atr
            elif price > last_pivot:
                # en yüksek noktayı güncelle (ama teyit etme!)
                last_pivot = price
                last_pivot_idx = i
                last_atr = atr

        elif direction == "down":
            # fiyat düşüyor
            if price >= (last_pivot + last_atr):
                # son pivot teyit edildi → bu bir dipti
                pivots[last_pivot_idx] = last_pivot
                direction = "up"
                last_pivot = price
                last_pivot_idx = i
                last_atr = atr
            elif price < last_pivot:
                # en düşük noktayı güncelle (ama teyit etme!)
                last_pivot = price
                last_pivot_idx = i
                last_atr = atr

    df["atr_zigzag"] = pivots
    return df

"""# Zigzag ATR High-Low"""

def atr_zigzag_two_columns(df, atr_col="atr", close_col="close", atr_mult=1):
    """
    ATR bazlı strict zigzag, high ve low pivotları ayrı sütunlarda.
    Ayrıca pivot teyidi hangi barda geldiğini ve kaç bar geciktiğini işaretler.

    Params:
        df : DataFrame
        atr_col : str -> ATR kolon adı
        close_col : str -> Kapanış fiyatı kolon adı
        atr_mult : float -> Kaç ATR kullanılacak (1, 2, 3 ...)
    """
    closes = df[close_col].values
    atrs = df[atr_col].values

    high_pivot = [None] * len(df)
    low_pivot = [None] * len(df)
    high_pivot_confirmed = [0] * len(df)
    low_pivot_confirmed = [0] * len(df)
    pivot_bars_ago = [None] * len(df)

    last_pivot = closes[0]
    last_atr = atrs[0]
    last_pivot_idx = 0
    direction = None  # "up" veya "down"

    for i in range(1, len(df)):
        price = closes[i]
        atr = atrs[i] * atr_mult  # ATR çarpanı uygulanıyor

        if direction is None:
            if price >= last_pivot + atr:
                direction = "up"
                last_pivot = closes[last_pivot_idx]
                high_pivot[last_pivot_idx] = last_pivot
            elif price <= last_pivot - atr:
                direction = "down"
                last_pivot = closes[last_pivot_idx]
                low_pivot[last_pivot_idx] = last_pivot

        elif direction == "up":
            if price <= (last_pivot - atr):
                # ✅ Tepe teyit edildi
                high_pivot[last_pivot_idx] = last_pivot
                high_pivot_confirmed[i] = 1
                pivot_bars_ago[i] = i - last_pivot_idx

                direction = "down"
                last_pivot = price
                last_pivot_idx = i
            elif price > last_pivot:
                # Tepe güncelle, teyit etme
                last_pivot = price
                last_pivot_idx = i

        elif direction == "down":
            if price >= (last_pivot + atr):
                # ✅ Dip teyit edildi
                low_pivot[last_pivot_idx] = last_pivot
                low_pivot_confirmed[i] = 1
                pivot_bars_ago[i] = i - last_pivot_idx

                direction = "up"
                last_pivot = price
                last_pivot_idx = i
            elif price < last_pivot:
                # Dip güncelle, teyit etme
                last_pivot = price
                last_pivot_idx = i

    df["high_pivot"] = high_pivot
    df["low_pivot"] = low_pivot
    df["high_pivot_confirmed"] = high_pivot_confirmed
    df["low_pivot_confirmed"] = low_pivot_confirmed
    df["pivot_bars_ago"] = pivot_bars_ago
    return df

def atr_zigzag_two_columns(df, atr_col="atr", close_col="close", atr_mult=1):
    """
    ATR bazlı strict zigzag, high ve low pivotları ayrı sütunlarda.
    Ayrıca pivot teyidi hangi barda geldiğini ve kaç bar geciktiğini işaretler.
    NaN değerler son pivot değerleriyle doldurulur.

    Params:
        df : DataFrame
        atr_col : str -> ATR kolon adı
        close_col : str -> Kapanış fiyatı kolon adı
        atr_mult : float -> Kaç ATR kullanılacak (1, 2, 3 ...)
    """
    closes = df[close_col].values
    atrs = df[atr_col].values

    high_pivot = [None] * len(df)
    low_pivot = [None] * len(df)
    high_pivot_confirmed = [0] * len(df)
    low_pivot_confirmed = [0] * len(df)
    pivot_bars_ago = [None] * len(df)

    last_pivot = closes[0]
    last_atr = atrs[0]
    last_pivot_idx = 0
    direction = None  # "up" veya "down"

    for i in range(1, len(df)):
        price = closes[i]
        atr = atrs[i] * atr_mult  # ATR çarpanı uygulanıyor

        if direction is None:
            if price >= last_pivot + atr:
                direction = "up"
                last_pivot = closes[last_pivot_idx]
                high_pivot[last_pivot_idx] = last_pivot
            elif price <= last_pivot - atr:
                direction = "down"
                last_pivot = closes[last_pivot_idx]
                low_pivot[last_pivot_idx] = last_pivot

        elif direction == "up":
            if price <= (last_pivot - atr):
                # ✅ Tepe teyit edildi
                high_pivot[last_pivot_idx] = last_pivot
                high_pivot_confirmed[i] = 1
                pivot_bars_ago[i] = i - last_pivot_idx

                direction = "down"
                last_pivot = price
                last_pivot_idx = i
            elif price > last_pivot:
                # Tepe güncelle, teyit etme
                last_pivot = price
                last_pivot_idx = i

        elif direction == "down":
            if price >= (last_pivot + atr):
                # ✅ Dip teyit edildi
                low_pivot[last_pivot_idx] = last_pivot
                low_pivot_confirmed[i] = 1
                pivot_bars_ago[i] = i - last_pivot_idx

                direction = "up"
                last_pivot = price
                last_pivot_idx = i
            elif price < last_pivot:
                # Dip güncelle, teyit etme
                last_pivot = price
                last_pivot_idx = i

    # Önce orijinal sütunları oluştur
    df["high_pivot"] = high_pivot
    df["low_pivot"] = low_pivot
    df["high_pivot_confirmed"] = high_pivot_confirmed
    df["low_pivot_confirmed"] = low_pivot_confirmed
    df["pivot_bars_ago"] = pivot_bars_ago

    # NaN değerleri doldurma işlemleri
    # high_pivot ve low_pivot için forward fill
    df["high_pivot_filled"] = df["high_pivot"].ffill()
    df["low_pivot_filled"] = df["low_pivot"].ffill()

    # high_pivot_confirmed ve low_pivot_confirmed için forward fill
    # Burada 0/1 değerlerini korumak için özel bir yaklaşım
    df["high_pivot_confirmed_filled"] = df["high_pivot_confirmed"].replace(to_replace=0, value=None).ffill().fillna(0).astype(int)
    df["low_pivot_confirmed_filled"] = df["low_pivot_confirmed"].replace(to_replace=0, value=None).ffill().fillna(0).astype(int)

    # pivot_bars_ago için özel doldurma - her satırda 1 artırarak
    pivot_bars_filled = []
    last_valid_value = None
    last_valid_index = None

    for i, value in enumerate(pivot_bars_ago):
        if value is not None:
            last_valid_value = value
            last_valid_index = i
            pivot_bars_filled.append(value)
        elif last_valid_value is not None:
            # NaN değeri, son geçerli değer + (mevcut index - son geçerli index)
            new_value = last_valid_value + (i - last_valid_index)
            pivot_bars_filled.append(new_value)
        else:
            # İlk değerler için
            pivot_bars_filled.append(None)

    df["pivot_bars_ago_filled"] = pivot_bars_filled

    return df

"""# DATAFRAME"""

#df = pd.read_csv('/content/TRX_USD_1h_2y.csv',header=0, skiprows=[1,2])
#df = df.rename(columns={'Price': 'datetime',})
#df.columns = df.columns.str.lower()
#df['datetime'] = pd.to_datetime(df['datetime'])

df = pd.read_csv('/content/BINANCE_SOLUSDT, 15.csv')
df.columns = df.columns.str.lower()
df['time'] = pd.to_datetime(df['time'])

df.tail()

df.info()

"""## Creating Main Columns"""

df['time'] = pd.to_datetime(df['time'], utc=True).dt.tz_convert("UTC")

df['rsi'] = calculate_rsi(df)
df['cat_rsi'] = categorize_rsi(df['rsi'])
df['rsi_40'] = calculate_rsi(df, window=40)
df['atr'] = calculate_atr(df)

bb = calculate_bollinger_bands(df)
df['bb_middle'] = bb['bb_middle']
df['bb_upper'] = bb['bb_upper']
df['bb_lower'] = bb['bb_lower']

dc = calculate_donchian_channel(df, window=20)
df['dc_upper_20'] = dc['dc_upper']
df['dc_lower_20'] = dc['dc_lower']
df['dc_middle_20'] = dc['dc_middle']

dc = calculate_donchian_channel(df, window=50)
df['dc_upper_50'] = dc['dc_upper']
df['dc_lower_50'] = dc['dc_lower']
df['dc_middle_50'] = dc['dc_middle']

df['sma_50'] = calculate_sma(df,window=50)
df['sma_200'] = calculate_sma(df,window=200)
df['sma_200_4h'] = calculate_sma(df,window=800)
df['sma_50_rate'] = df['close'] / df['sma_50']


df['trend_13_50']=determine_sma_trend(df, short_window=13, long_window=50)
df['trend_50_200']=determine_sma_trend(df, short_window=50, long_window=200)
df['trend_4h_50_200']=determine_sma_trend(df, short_window=200, long_window=800)

df['ema'] = calculate_ema(df, window=50)
df['ema_20'] = calculate_ema(df, window=20)
df['ema_50_rate'] = df['close'] / df['ema']
df['ema_20_rate'] = df['close'] / df['ema_20']

nw_bands = calculate_nadaraya_watson_envelope_optimized(df, bandwidth=8.0, multiplier=3.0, source_col='close', window_size=50)
df['nw'] = nw_bands['nw']
df['nw_upper'] = nw_bands['nw_upper']
df['nw_lower'] = nw_bands['nw_lower']




stoch = calculate_stochastic(df)
df['stoch_k'] = stoch['stoch_k']
df['stoch_d'] = stoch['stoch_d']

stoch_rsi = calculate_stoch_rsi(df)
df['stoch_rsi_k'] = stoch_rsi['stoch_rsi_k']
df['stoch_rsi_d'] = stoch_rsi['stoch_rsi_d']

macd = calculate_macd(df)
df['macd_line'] = macd['macd_line'] # blue line
df['macd_signal'] = macd['macd_signal'] # orange line
df['macd_hist'] = macd['macd_hist']


df['candle'] = df.apply(candle, axis=1)
df['candle_body'] = abs(df['close'] - df['open'])
df['candle_strength'] = df['candle_body'] / df['atr']
df['candle_class'] = df.apply(classify_strength, axis=1)

df['volume_price'] = df['volume'] / df['close']
df['volume_candle'] = df['volume'] * abs(df['close'] - df['open']) / df['close']

df = add_adx(df, period=14)

df = add_obv(df)

# local max ve min bul
df["zigzag_high"] = df["close"].iloc[argrelextrema(df["high"].values, np.greater_equal, order=10)[0]]
df["zigzag_low"]  = df["close"].iloc[argrelextrema(df["low"].values, np.less_equal, order=10)[0]]

# son görülen pivotları ileri taşı
df["last_high"] = df["zigzag_high"].ffill()
df["last_low"]  = df["zigzag_low"].ffill()

# pozisyon ve trend
df["zigzag_position"] = (df["close"] - df["last_low"]) / (df["last_high"] - df["last_low"]) * 100

df["high_trend"] = np.where(df["last_high"] > df["last_high"].shift(), "up",
                            np.where(df["last_high"] < df["last_high"].shift(), "down", None))

df["low_trend"] = np.where(df["last_low"] > df["last_low"].shift(), "up",
                           np.where(df["last_low"] < df["last_low"].shift(), "down", None))

df = atr_zigzag(df)

"""# Zigzag + Pivot Confirmed"""

df = atr_zigzag_two_columns(df, atr_col="atr", close_col="close", atr_mult=2)

# ATR Moves Analysis
def build_pivot_legs(df,
                     atr_col="atr",
                     high_pivot_col="high_pivot",
                     low_pivot_col="low_pivot",
                     high_col="high",
                     low_col="low",
                     close_col="close",
                     compute_entry_stats=True):
    """
    Zigzag pivotları (high_pivot/low_pivot) arasındaki her 'bacak' için
    ATR katını ve opsiyonel entry istatistiklerini hesaplar.

    Ayrıca df'teki tüm sütunları legs_df'e taşır (entry ve exit için ayrı sütunlar).
    """

    # 1) Pivotları sıraya koy
    pivots = []
    for idx, row in df.iterrows():
        if pd.notna(row.get(low_pivot_col, np.nan)):
            pivots.append({"type": "L", "idx": idx, "price": row[low_pivot_col], "atr": row[atr_col]})
        if pd.notna(row.get(high_pivot_col, np.nan)):
            pivots.append({"type": "H", "idx": idx, "price": row[high_pivot_col], "atr": row[atr_col]})
    pivots.sort(key=lambda x: x["idx"])

    # Aynı tip arka arkaya gelirse sonuncuyu tut
    cleaned = []
    for p in pivots:
        if not cleaned or cleaned[-1]["type"] != p["type"]:
            cleaned.append(p)
        else:
            cleaned[-1] = p
    pivots = cleaned

    legs = []
    for i in range(len(pivots) - 1):
        a = pivots[i]
        b = pivots[i + 1]

        start_idx   = a["idx"]
        end_idx     = b["idx"]
        start_type  = a["type"]
        end_type    = b["type"]
        direction   = "up" if start_type == "L" else "down"
        start_price = a["price"]
        end_price   = b["price"]
        start_atr   = a["atr"]
        bars        = int(end_idx - start_idx)
        move        = end_price - start_price
        move_abs    = abs(move)
        atr_mult    = move_abs / start_atr if (start_atr and start_atr > 0) else np.nan

        entry_idx = None
        entry_price = None
        bars_to_entry = None
        mfe_R = None
        triggered = False

        if compute_entry_stats and bars > 0 and (start_atr is not None) and start_atr > 0:
            # Entry kuralı: pivot + 1*ATR kırılması
            thresh = start_price + start_atr if direction == "up" else start_price - start_atr
            seg = df.loc[start_idx:end_idx]

            has_hl = (high_col in df.columns) and (low_col in df.columns)
            if direction == "up":
                hit = seg[seg[high_col] >= thresh] if has_hl else seg[seg[close_col] >= thresh]
            else:
                hit = seg[seg[low_col] <= thresh] if has_hl else seg[seg[close_col] <= thresh]

            if len(hit) > 0:
                entry_idx = hit.index[0]
                entry_price = thresh
                bars_to_entry = int(entry_idx - start_idx)
                triggered = True
                mfe_R = (end_price - entry_price) / start_atr if direction == "up" else (entry_price - end_price) / start_atr

        # df'teki entry ve exit satırlarını al
        entry_row = df.loc[start_idx].to_dict()
        exit_row = df.loc[end_idx].to_dict()

        # prefix ekle
        entry_prefixed = {f"entry_{k}": v for k, v in entry_row.items()}
        exit_prefixed = {f"exit_{k}": v for k, v in exit_row.items()}

        legs.append({
            "start_idx": start_idx,
            "end_idx": end_idx,
            "direction": direction,
            "start_type": start_type,
            "end_type": end_type,
            "start_price": start_price,
            "end_price": end_price,
            "start_atr": start_atr,
            "bars": bars,
            "price_move": move,
            "abs_move": move_abs,
            "atr_multiple": atr_mult,
            "entry_triggered": triggered,
            "entry_idx": entry_idx,
            "entry_price": entry_price,
            "bars_to_entry": bars_to_entry,
            "mfe_R_until_end_pivot": mfe_R,
            **entry_prefixed,
            **exit_prefixed
        })

    legs_df = pd.DataFrame(legs)
    return legs_df

legs_df = build_pivot_legs(df)

"""# Peaks-Valleys"""

# Yerel zirveler (High)
peaks, _ = find_peaks(df['high'], distance=20)   # distance = en az kaç bar aralıklı olsun
df['local_high'] = np.nan
df.loc[peaks, 'local_high'] = df['high']

# Yerel dipler (Low) için High'ın -Low versiyonu
valleys, _ = find_peaks(-df['low'], distance=10)
df['local_low'] = np.nan
df.loc[valleys, 'local_low'] = df['low']

# NaN’leri son pivot değeriyle doldur
df['local_high'] = df['local_high'].ffill()
df['local_low']  = df['local_low'].ffill()

"""# Derivative Variables

## Donchian Channel Positions
"""

df['dc_position_ratio_20'] = (df['close'] - df['dc_lower_20']) / (df['dc_upper_20'] - df['dc_lower_20']) * 100

conditions = [
    (df['dc_position_ratio_20'] < 10),
    (df['dc_position_ratio_20'] >= 10) & (df['dc_position_ratio_20'] < 25),
    (df['dc_position_ratio_20'] >= 25) & (df['dc_position_ratio_20'] < 40),
    (df['dc_position_ratio_20'] >= 40) & (df['dc_position_ratio_20'] < 60),
    (df['dc_position_ratio_20'] >= 60) & (df['dc_position_ratio_20'] < 75),
    (df['dc_position_ratio_20'] >= 75) & (df['dc_position_ratio_20'] < 90),
    (df['dc_position_ratio_20'] >= 90)
]

choices = [
    '0-10',
    '10-25',
    '25-40',
    '40-60',
    '60-75',
    '75-90',
    '90-100'
]

df['dc_position_20'] = np.select(conditions, choices, default='Bilinmeyen')

df['dc_position_ratio_50'] = (df['close'] - df['dc_lower_50']) / (df['dc_upper_50'] - df['dc_lower_50']) * 100


df['dc_position_50'] = np.select(conditions, choices, default='Bilinmeyen')


df['dc_breakout_20'] = df['high'] > df['dc_upper_20']
df['dc_breakdown_20'] = df['low'] < df['dc_lower_20']

df['dc_breakout_50'] = df['high'] > df['dc_upper_50']
df['dc_breakdown_50'] = df['low'] < df['dc_lower_50']

"""## BB Position"""

def bb_position(row):
    if row['high'] > row['bb_upper']:
        return 'above_upper'
    elif row['close'] > row['bb_middle']:
        return 'above_middle'
    elif row['close'] > row['bb_lower']:
        return 'below_middle'
    else:
        return 'below_lower'

df['bb_position'] = df.apply(bb_position, axis=1)

def calculate_bb_percentage_position(row):
    # Eğer herhangi bir bant değeri NaN ise veya bant genişliği sıfırsa (hata önleme)
    if pd.isna(row['bb_upper']) or pd.isna(row['bb_lower']) or pd.isna(row['close']):
        return np.nan

    band_range = row['bb_upper'] - row['bb_lower']

    # Bant genişliği sıfırsa veya çok küçükse (bölme hatasını önlemek için)
    if band_range <= 0.00000000000000001: # Küçük bir eşik değeri kullan
        if row['close'] > row['bb_upper']:
            return 'above_100' # Üst bandın üzerinde
        elif row['close'] < row['bb_lower']:
            return 'below_0'   # Alt bandın altında
        else:
            return 'within_bands_narrow' # Bantlar aşırı dar veya çakışık

    # Yüzdelik konumu hesapla (Bollinger Band Percentage)
    bbp = ((row['close'] - row['bb_lower']) / band_range) * 100

    # Kategorilere ayırma
    if bbp >= 100:
        return 'above_100'       # Fiyat üst bandın üzerinde
    elif bbp >= 75:
        return '75-100'          # Üst bandın %75'i ile %100'ü arasında
    elif bbp >= 50:
        return '50-75'           # Ortalamanın üzeri, %50 ile %75 arasında
    elif bbp >= 25:
        return '25-50'           # Ortalamanın altı, %25 ile %50 arasında
    elif bbp >= 0:
        return '0-25'            # Alt bandın %0'ı ile %25'i arasında
    else:
        return 'below_0'         # Fiyat alt bandın altında

df['bb_position'] = df.apply(calculate_bb_percentage_position, axis=1)

"""## Stochastic Position & Cross"""

def stoch_position(value):
    if value <= 20:
        return 'very_low'
    elif value <= 50:
        return 'low'
    elif value <= 80:
        return 'high'
    else:
        return 'very_high'

df['stoch_position'] = df['stoch_k'].apply(stoch_position)

df['stoch_cross_up'] = (df['stoch_k'] > df['stoch_d']) & (df['stoch_k'].shift(1) <= df['stoch_d'].shift(1))
df['stoch_cross_down'] = (df['stoch_k'] < df['stoch_d']) & (df['stoch_k'].shift(1) >= df['stoch_d'].shift(1))

"""## Nadaraya Watson Position"""

def nw_position(row):
    if row['close'] > row['nw_upper']:
        return 'above_upper'
    elif row['close'] > row['nw']:
        return 'above_middle'
    elif row['close'] > row['nw_lower']:
        return 'below_middle'
    else:
        return 'below_lower'

df['nw_position'] = df.apply(nw_position, axis=1)

"""## ADX Position"""

df['adx_category'] = None

# DataFrame üzerinde satır satır döngü yapalım
for index, row in df.iterrows():
    adx_value = row['adx']

    if pd.isna(adx_value): # Eğer ADX değeri NaN ise kategoriyi de NaN yap
        df.loc[index, 'adx_category'] = np.nan
    elif adx_value < 25:
        df.loc[index, 'adx_category'] = 'weak_trend'
    elif adx_value >= 25 and adx_value < 40: # 15 dahil, 30 hariç
        df.loc[index, 'adx_category'] = 'medium_trend'
    elif adx_value >= 40 and adx_value < 60: # 15 dahil, 30 hariç
        df.loc[index, 'adx_category'] = 'strong_trend'
    else: # adx_value >= 60
        df.loc[index, 'adx_category'] = 'super_strong_trend'

"""## SMA Cross"""

# Fark hesapla
df['diff_50_200'] = df['sma_50'] - df['sma_200']

# Önceki fark
df['diff_50_200_prev'] = df['diff_50_200'].shift(1)

# Yönlü crossover
df['sma_cross_up'] = (df['diff_50_200'] > 0) & (df['diff_50_200_prev'] <= 0)
df['sma_cross_down'] = (df['diff_50_200'] < 0) & (df['diff_50_200_prev'] >= 0)

# Fark hesapla
df['diff_50_200_4h'] = df['sma_200'] - df['sma_200_4h']

# Önceki fark
df['diff_50_200_4h_prev'] = df['diff_50_200'].shift(1)

# Yönlü crossover
df['sma_cross_up_4h'] = (df['diff_50_200_4h'] > 0) & (df['diff_50_200_4h_prev'] <= 0)
df['sma_cross_down_4h'] = (df['diff_50_200_4h'] < 0) & (df['diff_50_200_4h_prev'] >= 0)

"""## Percent ATR"""

df['pct_atr'] = df['atr'] / df['close'] * 100

"""# BB - DC Width Rate"""

df['bb_width_rate'] = df['bb_upper'] / df['bb_lower']
df['dc_50_width_rate'] = df['dc_upper_50'] / df['dc_lower_50']
df['dc_20_width_rate'] = df['dc_upper_20'] / df['dc_lower_20']

def width_rate_position_np(df, col, low_width, high_width):
    conditions = [
        df[col] < low_width,
        df[col] > high_width
    ]
    choices = ['narrow', 'wide']
    df[col + '_position'] = np.select(conditions, choices, default='middle-wide')
    return df

low_dc_width = df['dc_50_width_rate'].quantile(0.15)
high_dc_width = df['dc_50_width_rate'].quantile(0.85)
low_dc_width_20 = df['dc_20_width_rate'].quantile(0.15)
high_dc_width_20 = df['dc_20_width_rate'].quantile(0.85)
low_bb_width = df['bb_width_rate'].quantile(0.15)
high_bb_width = df['bb_width_rate'].quantile(0.85)

df = width_rate_position_np(df, 'dc_50_width_rate', low_dc_width, high_dc_width)
df = width_rate_position_np(df, 'dc_20_width_rate', low_dc_width_20, high_dc_width_20)
df = width_rate_position_np(df, 'bb_width_rate', low_bb_width, high_bb_width)

low_pct_atr = df['pct_atr'].quantile(0.15)
high_pct_atr = df['pct_atr'].quantile(0.85)
df = width_rate_position_np(df, 'pct_atr', low_pct_atr, high_pct_atr)

"""# BB Strategies - 1 Or 3 Touch - Trend or Not"""

def bb_touch_signal(df, touch_count=1, trend_filter=False, trend_col='trend_50_200', trend_direction='uptrend'):
    """
    BB üst banda veya alt banda temas sayısına göre Long/Short sinyali.

    Params:
        df: DataFrame with BB bands & trend
        touch_count: int (1 veya 3)
        trend_filter: bool (True → trend şartı aranır)
        trend_col: str (ör. 'sma_trend')
        trend_direction: 'uptrend' veya 'downtrend'

    Returns:
        pd.Series: True where signal occurs
    """
    df['bb_touch_upper'] = df['high'] >= df['bb_upper']
    df['bb_touch_lower'] = df['low'] <= df['bb_lower']

    # Son 'touch_count' bardaki temas toplamı
    touch_upper = sum([df['bb_touch_upper'].shift(i+1) for i in range(touch_count)])
    touch_lower = sum([df['bb_touch_lower'].shift(i+1) for i in range(touch_count)])

    signal_long = touch_upper >= touch_count
    signal_short = touch_lower >= touch_count

    if trend_filter:
        signal_long = signal_long & (df[trend_col] == trend_direction)
        signal_short = signal_short & (df[trend_col] != trend_direction)

    return pd.Series(signal_long, index=df.index), pd.Series(signal_short, index=df.index)

"""# DC Strategies - Trend or Not"""

def dc_breakout_signal(df, dc_upper='dc_upper_20', dc_lower='dc_lower_20',
                       trend_filter=False, trend_col='trend_50_200', trend_direction='uptrend'):
    """
    DC breakout sinyali.

    Params:
        dc_upper: Üst kanal kolonu
        dc_lower: Alt kanal kolonu
        trend_filter: Trend filtresi kullanılacak mı?
        trend_col: Trend kolonu ismi
        trend_direction: Beklenen trend yönü ('uptrend' veya 'downtrend')

    Returns:
        long_signal, short_signal: pd.Series (bool)
    """
    # DC breakout: şu anki high, bir önceki üst bandın üstüne çıktı mı?
    breakout_upper = df['high'] > df[dc_upper].shift(1)
    breakout_lower = df['low'] < df[dc_lower].shift(1)

    signal_long = breakout_upper
    signal_short = breakout_lower

    if trend_filter:
        signal_long &= (df[trend_col] == trend_direction)
        signal_short &= (df[trend_col] != trend_direction)

    return pd.Series(signal_long, index=df.index), pd.Series(signal_short, index=df.index)

"""# NW Strategies


"""

def nw_breakout_signal(df, band_ratio=0.2):
    """
    Nadaraya-Watson breakout sinyali.
    NW bandının belirli bir oran üzerinde aşılması durumunda long/short sinyali üretir.

    Args:
        df (pd.DataFrame): Fiyat verisi içeren DataFrame.
        band_ratio (float): Band genişliğinin yüzdesi. Örn. 0.2 → %20

    Returns:
        pd.Series: signal_long, signal_short
    """
    band_width = df['nw_upper'] - df['nw_lower']

    excess_upper = df['high'] > df['nw_upper'].shift(1) + band_ratio * band_width.shift(1)
    excess_lower = df['low'] < df['nw_lower'].shift(1) - band_ratio * band_width.shift(1)

    signal_long = excess_lower
    signal_short = excess_upper

    return pd.Series(signal_long, index=df.index), pd.Series(signal_short, index=df.index)

"""# MACD - Stochastic and Two Dots Signal"""

def macd_signal_generator_bool(macd_df):
    """
    MACD göstergelerine göre True/False alım/satım sinyalleri üretir.

    Args:
        macd_df (pd.DataFrame): 'macd_line' ve 'macd_signal' sütunlarını içeren MACD DataFrame'i.

    Returns:
        tuple: (macd_long_signal, macd_short_signal)
               macd_long_signal (pd.Series): Long sinyallerini içeren Series (True/False).
               macd_short_signal (pd.Series): Short sinyallerini içeren Series (True/False).
    """
    # Long sinyali (MACD çizgisi sinyal çizgisini yukarı keser)
    long_signals = (macd_df['macd_line'] > macd_df['macd_signal']) & \
                   (macd_df['macd_line'].shift(1) <= macd_df['macd_signal'].shift(1))

    # Short sinyali (MACD çizgisi sinyal çizgisini aşağı keser)
    short_signals = (macd_df['macd_line'] < macd_df['macd_signal']) & \
                    (macd_df['macd_line'].shift(1) >= macd_df['macd_signal'].shift(1))

    return long_signals, short_signals

def stoch_signal_generator_bool(stoch_df):
    """
    Stokastik göstergelere göre True/False alım/satım sinyalleri üretir.

    Args:
        stoch_df (pd.DataFrame): 'stoch_k' ve 'stoch_d' sütunlarını içeren Stokastik DataFrame'i.

    Returns:
        tuple: (stoch_long_signal, stoch_short_signal)
               stoch_long_signal (pd.Series): Long sinyallerini içeren Series (True/False).
               stoch_short_signal (pd.Series): Short sinyallerini içeren Series (True/False).
    """
    # Yukarı kesişim (long sinyali)
    stoch_cross_up = (stoch_df['stoch_k'] > stoch_df['stoch_d']) & \
                     (stoch_df['stoch_k'].shift(1) <= stoch_df['stoch_d'].shift(1))

    # Aşağı kesişim (short sinyali)
    stoch_cross_down = (stoch_df['stoch_k'] < stoch_df['stoch_d']) & \
                       (stoch_df['stoch_k'].shift(1) >= stoch_df['stoch_d'].shift(1))

    return stoch_cross_up, stoch_cross_down

def two_dots_signal_bool(macd_signals, stoch_signals, window=5):
    """
    MACD ve Stokastik sinyallerini birleştirerek yeni bir True/False sinyal üretir.
    Her iki sinyal de belirli bir pencere içinde aynı yönde ise True sinyal üretir.

    Args:
        macd_signals (tuple): macd_signal_generator_bool'dan dönen (long_signals, short_signals) tuple'ı.
        stoch_signals (tuple): stoch_signal_generator_bool'dan dönen (long_signals, short_signals) tuple'ı.
        window (int): İki sinyalin aynı yönde oluşması için bakılacak geçmiş veri birimi sayısı.

    Returns:
        tuple: (two_dots_long_signal, two_dots_short_signal)
               two_dots_long_signal (pd.Series): Birleşik long sinyallerini içeren Series (True/False).
               two_dots_short_signal (pd.Series): Birleşik short sinyallerini içeren Series (True/False).
    """
    # Gelen sinyalleri ayır
    macd_long_signal, macd_short_signal = macd_signals
    stoch_long_signal, stoch_short_signal = stoch_signals

    combined_long_signals = pd.Series(False, index=macd_long_signal.index)
    combined_short_signals = pd.Series(False, index=macd_long_signal.index)

    for i in range(len(macd_long_signal)):
        # Long sinyali için pencere kontrolü
        long_conditions_met = False
        for j in range(max(0, i - window + 1), i + 1):
            if macd_long_signal.iloc[j] and stoch_long_signal.iloc[j]:
                long_conditions_met = True
                break

        if long_conditions_met:
            combined_long_signals.iloc[i] = True

        # Short sinyali için pencere kontrolü
        short_conditions_met = False
        for j in range(max(0, i - window + 1), i + 1):
            if macd_short_signal.iloc[j] and stoch_short_signal.iloc[j]:
                short_conditions_met = True
                break

        if short_conditions_met:
            combined_short_signals.iloc[i] = True

    return combined_long_signals, combined_short_signals

# MACD Sinyallerini al
long_macd_signal, short_macd_signal = macd_signal_generator_bool(df)
df['macd_long_signal'] = long_macd_signal
df['macd_short_signal'] = short_macd_signal

# Stokastik Sinyallerini al
long_stoch_signal, short_stoch_signal = stoch_signal_generator_bool(df)
df['stoch_long_signal'] = long_stoch_signal
df['stoch_short_signal'] = short_stoch_signal

two_dots_long, two_dots_short = two_dots_signal_bool(
    (df['macd_long_signal'], df['macd_short_signal']),
    (df['stoch_long_signal'], df['stoch_short_signal']),
    window=5
)

df['two_dots_long'] = two_dots_long
df['two_dots_short'] = two_dots_short

# DC 20 breakout
long_dc20, short_dc20 = dc_breakout_signal(df, 'dc_upper_20', 'dc_lower_20',trend_col='trend_50_200', trend_filter=True)
df['dc_breakout_20'] = long_dc20
df['dc_breakdown_20'] = short_dc20
# DC 50 breakout
long_dc50, short_dc50 = dc_breakout_signal(df, 'dc_upper_50', 'dc_lower_50', trend_filter=True)
df['dc_breakout_50'] = long_dc50
df['dc_breakdown_50'] = short_dc50


# BB bir kere temas long/short
long1, short1 = bb_touch_signal(df, touch_count=1, trend_filter=True)
df['bb_1_touch_long'] = long1
df['bb_1_touch_short'] = short1
# BB üç kere temas long/short
long3, short3 = bb_touch_signal(df, touch_count=3, trend_filter=True)
df['bb_3_touch_long'] = long3
df['bb_3_touch_short'] = short3


# NW signal
long_nw, short_nw = nw_breakout_signal(df, band_ratio=0.2)
df['nw_long'] = long_nw
df['nw_short'] = short_nw

"""# BB.ELF Signal"""

# Long tarafı için
no_long_touch_last_10 = df['bb_3_touch_long'].shift(1).rolling(window=10).sum() == 0
df['bb_3_touch_long_clean'] = df['bb_3_touch_long'] & no_long_touch_last_10

# Short tarafı için
no_short_touch_last_10 = df['bb_3_touch_short'].shift(1).rolling(window=10).sum() == 0
df['bb_3_touch_short_clean'] = df['bb_3_touch_short'] & no_short_touch_last_10

# Long tarafı için
no_long_touch_last_10 = df['bb_1_touch_long'].shift(1).rolling(window=10).sum() == 0
df['bb_1_touch_long_clean'] = df['bb_1_touch_long'] & no_long_touch_last_10

# Short tarafı için
no_short_touch_last_10 = df['bb_1_touch_short'].shift(1).rolling(window=10).sum() == 0
df['bb_1_touch_short_clean'] = df['bb_1_touch_short'] & no_short_touch_last_10

"""# DC Clean Signal"""

#20
df['dc_breakout_clean_20'] = df['dc_breakout_20'] & (
    df['dc_breakout_20'].shift(1).rolling(window=10).sum() == 0
)

df['dc_breakdown_clean_20'] = df['dc_breakdown_20'] & (
    df['dc_breakdown_20'].shift(1).rolling(window=10).sum() == 0
)

#55
df['dc_breakout_clean_50'] = df['dc_breakout_50'] & (
    df['dc_breakout_50'].shift(1).rolling(window=10).sum() == 0
)

df['dc_breakdown_clean_50'] = df['dc_breakdown_50'] & (
    df['dc_breakdown_50'].shift(1).rolling(window=10).sum() == 0
)

"""# NW Clean Signal"""

# Ardışık iki nw_long sinyali (mevcut ve bir önceki satır True)
consecutive_nw_long = df['nw_long'] & df['nw_long'].shift(-1)

# Sonraki 5 satırda nw_long olup olmadığını kontrol et (0 ise temiz)
no_nw_long_in_next_5 = (df['nw_long'].shift(1).rolling(window=5, min_periods=1).sum() == 0)

# Sinyal oluşumu: Ardışık iki True VE sonraki 5 satır temiz
df['nw_long_clean'] = consecutive_nw_long & no_nw_long_in_next_5

# Ardışık iki nw_long sinyali (mevcut ve bir önceki satır True)
consecutive_nw_short = df['nw_short'] & df['nw_short'].shift(-1)

# Sonraki 5 satırda nw_long olup olmadığını kontrol et (0 ise temiz)
no_nw_short_in_next_5 = (df['nw_short'].shift(1).rolling(window=5, min_periods=1).sum() == 0)

# Sinyal oluşumu: Ardışık iki True VE sonraki 5 satır temiz
df['nw_short_clean'] = consecutive_nw_short & no_nw_short_in_next_5

"""# PIVOT SIGNALS"""

df['pivot_up'] = False
df['pivot_down'] = False

df.loc[(df['low_pivot_confirmed']) & (df['trend_13_50']== 'uptrend'), 'pivot_up'] = True
df.loc[(df['high_pivot_confirmed']) & (df['trend_13_50']== 'downtrend'), 'pivot_down'] = True

"""# Target and Results"""

# It determined according to percent atr levels.
df['x'] = np.minimum(
    np.maximum(df['close'] * df['pct_atr'].quantile(0.05)/100, 1 * df['atr']),
    df['close'] * df['pct_atr'].quantile(0.9)/100
)

x_levels = [-5, -4, -3, -2, -1, 1, 2, 3, 4, 5]

for level in x_levels:
    df[f'target_{level}x'] = df['close'] + level * df['x']

def calculate_bars_to_hit_updated(df, max_bars=100, verbose=True):
    for i in range(len(df)):
        entry = df.loc[i, 'close']
        x = df.loc[i, 'x']
        for level in x_levels:
            target_price = entry + level * x
            for j in range(1, max_bars + 1):
                if i + j >= len(df):
                    break
                high = df.loc[i + j, 'high']
                low = df.loc[i + j, 'low']
                if (level > 0 and high >= target_price) or (level < 0 and low <= target_price):
                    df.at[i, f'{level}x_bar'] = j
                    break

    # Inform per 1000 rows.
        if verbose and i % 1000 == 0 and i != 0:
            print(f"{i} satır tamamlandı...")

    return df

#x_levels = [ -2, -1, 1, 2 ]
#x_levels = [ -3, -1, 1, 3 ]
#x_levels = [ -4, -1,  2,  4 ]
#x_levels = [ -4, -3, -2, -1, 1, 2, 3, 4 ]
x_levels = [ -5, -4, -3, -2, -1, 1, 2, 3, 4, 5 ]
df = calculate_bars_to_hit_updated(df)

x_levels = [-5, -4, -3, -2, -1, 1, 2, 3, 4, 5]
df = df[
    [col for col in df.columns if 'x_bar' not in col] +
    [f"{i}x_bar" for i in x_levels if f"{i}x_bar" in df.columns]
]

# MACD Sinyallerini al
long_macd_signal, short_macd_signal = macd_signal_generator_bool(df)
df['macd_long_signal'] = long_macd_signal
df['macd_short_signal'] = short_macd_signal

# Stokastik Sinyallerini al
long_stoch_signal, short_stoch_signal = stoch_signal_generator_bool(df)
df['stoch_long_signal'] = long_stoch_signal
df['stoch_short_signal'] = short_stoch_signal

two_dots_long, two_dots_short = two_dots_signal_bool(
    (df['macd_long_signal'], df['macd_short_signal']),
    (df['stoch_long_signal'], df['stoch_short_signal']),
    window=5
)

df['two_dots_long'] = two_dots_long
df['two_dots_short'] = two_dots_short

# DC 20 breakout
long_dc20, short_dc20 = dc_breakout_signal(df, 'dc_upper_20', 'dc_lower_20',trend_col='trend_50_200', trend_filter=True)
df['dc_breakout_20'] = long_dc20
df['dc_breakdown_20'] = short_dc20
# DC 50 breakout
long_dc50, short_dc50 = dc_breakout_signal(df, 'dc_upper_50', 'dc_lower_50', trend_filter=True)
df['dc_breakout_50'] = long_dc50
df['dc_breakdown_50'] = short_dc50


# BB bir kere temas long/short
long1, short1 = bb_touch_signal(df, touch_count=1, trend_filter=True)
df['bb_1_touch_long'] = long1
df['bb_1_touch_short'] = short1
# BB üç kere temas long/short
long3, short3 = bb_touch_signal(df, touch_count=3, trend_filter=True)
df['bb_3_touch_long'] = long3
df['bb_3_touch_short'] = short3


# NW signal
long_nw, short_nw = nw_breakout_signal(df, band_ratio=0.2)
df['nw_long'] = long_nw
df['nw_short'] = short_nw

"""# BB.ELF Signal"""

# Long tarafı için
no_long_touch_last_10 = df['bb_3_touch_long'].shift(1).rolling(window=10).sum() == 0
df['bb_3_touch_long_clean'] = df['bb_3_touch_long'] & no_long_touch_last_10

# Short tarafı için
no_short_touch_last_10 = df['bb_3_touch_short'].shift(1).rolling(window=10).sum() == 0
df['bb_3_touch_short_clean'] = df['bb_3_touch_short'] & no_short_touch_last_10

# Long tarafı için
no_long_touch_last_10 = df['bb_1_touch_long'].shift(1).rolling(window=10).sum() == 0
df['bb_1_touch_long_clean'] = df['bb_1_touch_long'] & no_long_touch_last_10

# Short tarafı için
no_short_touch_last_10 = df['bb_1_touch_short'].shift(1).rolling(window=10).sum() == 0
df['bb_1_touch_short_clean'] = df['bb_1_touch_short'] & no_short_touch_last_10

"""# DC Clean Signal"""

#20
df['dc_breakout_clean_20'] = df['dc_breakout_20'] & (
    df['dc_breakout_20'].shift(1).rolling(window=10).sum() == 0
)

df['dc_breakdown_clean_20'] = df['dc_breakdown_20'] & (
    df['dc_breakdown_20'].shift(1).rolling(window=10).sum() == 0
)

#55
df['dc_breakout_clean_50'] = df['dc_breakout_50'] & (
    df['dc_breakout_50'].shift(1).rolling(window=10).sum() == 0
)

df['dc_breakdown_clean_50'] = df['dc_breakdown_50'] & (
    df['dc_breakdown_50'].shift(1).rolling(window=10).sum() == 0
)

"""# NW Clean Signal"""

# Ardışık iki nw_long sinyali (mevcut ve bir önceki satır True)
consecutive_nw_long = df['nw_long'] & df['nw_long'].shift(-1)

# Sonraki 5 satırda nw_long olup olmadığını kontrol et (0 ise temiz)
no_nw_long_in_next_5 = (df['nw_long'].shift(1).rolling(window=5, min_periods=1).sum() == 0)

# Sinyal oluşumu: Ardışık iki True VE sonraki 5 satır temiz
df['nw_long_clean'] = consecutive_nw_long & no_nw_long_in_next_5

# Ardışık iki nw_long sinyali (mevcut ve bir önceki satır True)
consecutive_nw_short = df['nw_short'] & df['nw_short'].shift(-1)

# Sonraki 5 satırda nw_long olup olmadığını kontrol et (0 ise temiz)
no_nw_short_in_next_5 = (df['nw_short'].shift(1).rolling(window=5, min_periods=1).sum() == 0)

# Sinyal oluşumu: Ardışık iki True VE sonraki 5 satır temiz
df['nw_short_clean'] = consecutive_nw_short & no_nw_short_in_next_5

"""# PIVOT SIGNALS"""

df['pivot_up'] = False
df['pivot_down'] = False

df.loc[(df['low_pivot_confirmed']) & (df['trend_13_50']== 'uptrend'), 'pivot_up'] = True
df.loc[(df['high_pivot_confirmed']) & (df['trend_13_50']== 'downtrend'), 'pivot_down'] = True

"""# Signal Standard Results"""

def compare_x_bars(df, signal_col, x_levels, signal_type='long'):
    """
    Pozitif ve negatif x_bar sütunlarını ikili karşılaştırır. Long/Short destekli.

    Args:
        df (pd.DataFrame): Ana DataFrame
        signal_col (str): Sinyal sütunu adı
        x_levels (list): x seviyeleri (örn: [-10, -5, ..., 10])
        signal_type (str): 'long' veya 'short'

    Returns:
        pd.DataFrame: Sonuç tablosu
    """
    results = []
    df_signal = df[df[signal_col] == True].copy()

    pos_x = [x for x in x_levels if x > 0]
    neg_x = [x for x in x_levels if x < 0]

    for px in pos_x:
        for nx in neg_x:
            pos_col = f"{px}x_bar"
            neg_col = f"{nx}x_bar"

            if pos_col in df_signal.columns and neg_col in df_signal.columns:
                df_valid = df_signal.copy()

                mask = (df_valid[pos_col].isna() ^ df_valid[neg_col].isna()) | \
                       (df_valid[pos_col].notna() & df_valid[neg_col].notna())

                df_valid = df_valid[mask]
                df_valid[pos_col] = df_valid[pos_col].fillna(999)
                df_valid[neg_col] = df_valid[neg_col].fillna(999)

                if signal_type == 'long':
                    tp_first = (df_valid[pos_col] < df_valid[neg_col]).sum()
                    sl_first = (df_valid[pos_col] > df_valid[neg_col]).sum()
                    profit_score = ((tp_first * px + sl_first * nx) / len(df_valid)) * 100 if len(df_valid) > 0 else 0.0

                    results.append({
                        "tp_level": f"{px}x_bar",
                        "sl_level": f"{nx}x_bar",
                        "tp_first": tp_first,
                        "sl_first": sl_first,
                        "total": len(df_valid),
                        "tp_rate": round((tp_first / len(df_valid)) * 100, 2),
                        "sl_rate": round((sl_first / len(df_valid)) * 100, 2),
                        "profit_score": round(profit_score, 2)
                    })

                elif signal_type == 'short':
                    tp_first = (df_valid[neg_col] < df_valid[pos_col]).sum()
                    sl_first = (df_valid[neg_col] > df_valid[pos_col]).sum()
                    profit_score = -((tp_first * nx + sl_first * px) / len(df_valid)) * 100 if len(df_valid) > 0 else 0.0

                    results.append({
                        "tp_level": f"{nx}x_bar",  # TP seviyesi negatif olmalı
                        "sl_level": f"{px}x_bar",  # SL seviyesi pozitif olmalı
                        "tp_first": tp_first,
                        "sl_first": sl_first,
                        "total": len(df_valid),
                        "tp_rate": round((tp_first / len(df_valid)) * 100, 2),
                        "sl_rate": round((sl_first / len(df_valid)) * 100, 2),
                        "profit_score": round(profit_score, 2)
                    })

    return pd.DataFrame(results)

"""# DFF and NAN VALUES"""

dff = df.copy()

dff.loc[:, dff.columns.str.contains('x_bar')] = dff.loc[:, dff.columns.str.contains('x_bar')].fillna(999)

"""# Signal Standard Results"""

def compare_x_bars(df, signal_col, x_levels, signal_type='long'):
    """
    Pozitif ve negatif x_bar sütunlarını ikili karşılaştırır. Long/Short destekli.

    Args:
        df (pd.DataFrame): Ana DataFrame
        signal_col (str): Sinyal sütunu adı
        x_levels (list): x seviyeleri (örn: [-10, -5, ..., 10])
        signal_type (str): 'long' veya 'short'

    Returns:
        pd.DataFrame: Sonuç tablosu
    """
    results = []
    df_signal = df[df[signal_col] == True].copy()

    pos_x = [x for x in x_levels if x > 0]
    neg_x = [x for x in x_levels if x < 0]

    for px in pos_x:
        for nx in neg_x:
            pos_col = f"{px}x_bar"
            neg_col = f"{nx}x_bar"

            if pos_col in df_signal.columns and neg_col in df_signal.columns:
                df_valid = df_signal.copy()

                mask = (df_valid[pos_col].isna() ^ df_valid[neg_col].isna()) | \
                       (df_valid[pos_col].notna() & df_valid[neg_col].notna())

                df_valid = df_valid[mask]
                df_valid[pos_col] = df_valid[pos_col].fillna(999)
                df_valid[neg_col] = df_valid[neg_col].fillna(999)

                if signal_type == 'long':
                    tp_first = (df_valid[pos_col] < df_valid[neg_col]).sum()
                    sl_first = (df_valid[pos_col] > df_valid[neg_col]).sum()
                    profit_score = ((tp_first * px + sl_first * nx) / len(df_valid)) * 100 if len(df_valid) > 0 else 0.0

                    results.append({
                        "tp_level": f"{px}x_bar",
                        "sl_level": f"{nx}x_bar",
                        "tp_first": tp_first,
                        "sl_first": sl_first,
                        "total": len(df_valid),
                        "tp_rate": round((tp_first / len(df_valid)) * 100, 2),
                        "sl_rate": round((sl_first / len(df_valid)) * 100, 2),
                        "profit_score": round(profit_score, 2)
                    })

                elif signal_type == 'short':
                    tp_first = (df_valid[neg_col] < df_valid[pos_col]).sum()
                    sl_first = (df_valid[neg_col] > df_valid[pos_col]).sum()
                    profit_score = -((tp_first * nx + sl_first * px) / len(df_valid)) * 100 if len(df_valid) > 0 else 0.0

                    results.append({
                        "tp_level": f"{nx}x_bar",  # TP seviyesi negatif olmalı
                        "sl_level": f"{px}x_bar",  # SL seviyesi pozitif olmalı
                        "tp_first": tp_first,
                        "sl_first": sl_first,
                        "total": len(df_valid),
                        "tp_rate": round((tp_first / len(df_valid)) * 100, 2),
                        "sl_rate": round((sl_first / len(df_valid)) * 100, 2),
                        "profit_score": round(profit_score, 2)
                    })

    return pd.DataFrame(results)

"""# Pivot 1-2-3 ATR"""

df = atr_zigzag_two_columns(df, atr_col="atr", close_col="close", atr_mult=1)

legs_df = build_pivot_legs(df)

"""#ML MODEL VARIABLES

* dc_position_20 - dc_position_50 (85-100) +
* cat_rsi - rsi +
* adx - adx_category +
* bb_position +
* ema_rate +
* sma_rate +
* trend13 - trend50 +
* pct_atr +
* nadaraya_watson_envelope_position +
* candle class +
* bb_touch, dc_touch +


* high_pivot_confirmed - low_pivot_confirmed - pivot_bars_Ago-'high_pivot_filled', 'low_pivot_filled', 'high_pivot_confirmed_filled', 'low_pivot_confirmed_filled', 'pivot_bars_ago_filled', 'pivot_up', 'pivot_down' +

* 4-2, 4-1, 3-1, 2-1, 2-2, 1-2, 1-3, 1-4, 2-4 +

* bb_upper/bb_lower -  dc_upper/dc_lower and categorical
* Zigzagtan sonra kaçıncı atrde hangi yönde

* Normalization / Standardization
* Feature Importance
* y_proba
* 5 farklı paritede dene.
"""

dff = df.copy()
dff.loc[:, dff.columns.str.contains('x_bar')] = dff.loc[:, dff.columns.str.contains('x_bar')].fillna(999)



dff.columns[dff.columns.str.contains('pivot')]



"""# Target Variables"""

dff.columns[dff.columns.str.contains('x_bar')]

dff[['5_2_atr_long','5_2_atr_short','4_2_atr_long','4_2_atr_short','2_2_atr_long','2_2_atr_short',
     '4_1_atr_long','4_1_atr_short','3_1_atr_long','3_1_atr_short','2_1_atr_long','2_1_atr_short']] = 0

dff.loc[(dff['5x_bar'] < dff['-2x_bar']) ,'5_2_atr_long'] = 1
dff.loc[(dff['-5x_bar'] < dff['2x_bar']) ,'5_2_atr_short'] = 1

dff.loc[(dff['4x_bar'] < dff['-2x_bar']) ,'4_2_atr_long'] = 1
dff.loc[(dff['-4x_bar'] < dff['2x_bar']) ,'4_2_atr_short'] = 1

dff.loc[(dff['2x_bar'] < dff['-2x_bar']) ,'2_2_atr_long'] = 1
dff.loc[(dff['-2x_bar'] < dff['2x_bar']) ,'2_2_atr_short'] = 1

dff.loc[(dff['4x_bar'] < dff['-1x_bar']) ,'4_1_atr_long'] = 1
dff.loc[(dff['-4x_bar'] < dff['1x_bar']) ,'4_1_atr_short'] = 1

dff.loc[(dff['3x_bar'] < dff['-1x_bar']) ,'3_1_atr_long'] = 1
dff.loc[(dff['-3x_bar'] < dff['1x_bar']) ,'3_1_atr_short'] = 1

dff.loc[(dff['2x_bar'] < dff['-1x_bar']) ,'2_1_atr_long'] = 1
dff.loc[(dff['-2x_bar'] < dff['1x_bar']) ,'2_1_atr_short'] = 1

"""# Explorer Data Analysis

## Catching Numerical and Categorical Variables
"""

def grab_col_names(dataframe, cat_th=10, car_th=20):
    # cat_cols, cat_but_car
    cat_cols= [col for col in dataframe.columns if dataframe[col].dtypes == 'O']
    num_but_cat = [col for col in dataframe.columns if dataframe[col].dtypes != 'O' and
                   dataframe[col].nunique() < cat_th]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].dtypes == 'O' and
                   dataframe[col].nunique() > car_th]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != 'O']
    num_cols = [col for col in num_cols if col not in num_but_cat ]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f"cat_cols: {len(cat_cols)}")
    print(f"num_cols: {len(num_cols)}")
    print(f"cat_but_car: {len(cat_but_car)}")
    print(f"num_but_cat: {len(num_but_cat)}")
    return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = grab_col_names(dff)

cat_cols

cat_cols = ['trend_13_50','candle_class','dc_position_20','dc_position_50','bb_position','adx_category','cat_rsi','bb_touch_upper','bb_touch_lower','bb_3_touch_long_clean','bb_3_touch_short_clean','dc_breakout_clean_50','dc_breakdown_clean_50',
            'dc_50_width_rate_position', 'dc_20_width_rate_position', 'bb_width_rate_position', 'pct_atr_position']
            # backtestlerdeki filtre sütunları ayarlayalım mapping ile birlikte

num_cols

num_cols = ['rsi','rsi_40','sma_50_rate','bb_width_rate','dc_50_width_rate',
            'dc_20_width_rate','adx']

dff['dc_50_width_rate'].describe([0.05, 0.15,  0.2, 0.85, 0.9, 0.95])

"""# Scaling"""

X_scaled = MinMaxScaler().fit_transform(dff[num_cols])
dff[num_cols] = pd.DataFrame(X_scaled, columns=dff[num_cols].columns)
dff.head()

target_cols = ['5_2_atr_long','5_2_atr_short','4_2_atr_long','4_2_atr_short','2_2_atr_long','2_2_atr_short',
               '4_1_atr_long','4_1_atr_short','3_1_atr_long','3_1_atr_short','2_1_atr_long','2_1_atr_short']

main_cols = ['open','time','high', 'low', 'close']

"""# Encoding"""

encoder = OneHotEncoder(drop="first", handle_unknown="ignore")

X_encoded = encoder.fit_transform(dff[cat_cols])

X_encoded = pd.DataFrame(X_encoded.toarray(),
                         columns=encoder.get_feature_names_out(cat_cols),
                         index=dff.index)

dff = pd.concat([dff[num_cols + target_cols], X_encoded], axis=1)

dff.columns



dff = dff[(dff.index > 200) & (dff.index < (len(df) - 100))]

"""# Model"""

target = '4_2_atr_short'
y = dff[target]
X = dff.drop(target_cols, axis=1)

X_train, X_test, y_train, y_test  =train_test_split(X, y, test_size=0.25, random_state=234)

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy  = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

print(classification_report(y_test, y_pred))

"""### Random Over Sampling"""

ros = RandomOverSampler(sampling_strategy='minority')
X_ros, y_ros = ros.fit_resample(X_train, y_train)
y_ros.value_counts()

model.fit(X_ros, y_ros)
y_pred = model.predict(X_test)
print("Random Over Sampling Classification Report".center(70), '\n\n',classification_report(y_test, y_pred))

"""### ADASYN (Adaptive Synthetic Sampling)"""

adasyn = ADASYN(sampling_strategy='minority')
X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)
y_adasyn.value_counts()

model.fit(X_adasyn, y_adasyn)
y_pred = model.predict(X_test)
print("ADASYN Sampling Classification Report".center(70), '\n\n',classification_report(y_test, y_pred))

"""### SMOTE Sampling"""

smote = SMOTE()
X_smote, y_smote = smote.fit_resample(X_train, y_train)
y_smote.value_counts()

model.fit(X_smote, y_smote)
y_pred = model.predict(X_test)
print("SMOTE Sampling Classification Report".center(70), '\n\n',classification_report(y_test, y_pred))

"""# Feature Importance Levels"""

def plot_confusion_matrix(cm, classes,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):

    plt.rcParams.update({'font.size': 10})
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title,fontdict={'size':'16'})
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45,fontsize=9,color="blue")
    plt.yticks(tick_marks, classes,fontsize=9,color="blue")
    rc('font', weight='bold')
    fmt = '.1f'
    thresh = cm.max()
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="red")

    plt.ylabel('True label',fontdict={'size':'10'})
    plt.xlabel('Predicted label',fontdict={'size':'10'})
    plt.tight_layout()

plot_confusion_matrix(confusion_matrix(y_test, y_pred=y_pred), classes=['No Fraud','Fraud'],
                      title='Confusion matrix')

coefficients = model.coef_[0]  # İkili sınıflandırma için
print("Katsayılar:", coefficients)

# Mutlak değerlerle önem sıralaması
feature_importance = np.abs(coefficients)
print("Özellik önemleri (mutlak değer):", feature_importance)

def plot_importance(model, features, num=None, save=False, use_abs=True, show_percentage=False):
    """
    Logistic Regression modeli için özellik önemlerini görselleştirir

    Parameters:
    - model: Eğitilmiş LogisticRegression modeli
    - features: Özellik DataFrame'i (X)
    - num: Gösterilecek özellik sayısı (varsayılan: tüm özellikler)
    - save: Grafiği kaydet (True/False)
    - use_abs: Mutlak değer kullan (True/False)
    - show_percentage: Yüzdelik gösterim kullan (True/False)
    """

    if num is None:
        num = len(features.columns)

    # Katsayıları al (ikili sınıflandırma için [0] indeksi)
    if len(model.coef_.shape) > 1:
        coefficients = model.coef_[0]
    else:
        coefficients = model.coef_

    # Mutlak değer kullanılıp kullanılmayacağına karar ver
    if use_abs:
        importance_values = np.abs(coefficients)
        title = 'Feature Importance'
    else:
        importance_values = coefficients
        title = 'Feature Coefficients'

    # Yüzdelik hesaplama
    if show_percentage and use_abs:
        # Katkı yüzdesi formülü: (|katsayı_i| / Σ|tüm_katsayılar|) × 100
        total_importance = np.sum(np.abs(coefficients))
        importance_values = (np.abs(coefficients) / total_importance) * 100
        title += ' (%)'
        x_label = 'Yüzde Katkı (%)'
    elif show_percentage and not use_abs:
        print("Uyarı: Negatif katsayılar olduğunda yüzdelik hesaplama önerilmez!")
        x_label = 'Coefficient Value'
    else:
        x_label = 'Importance Value'

    # DataFrame oluştur
    feature_imp = pd.DataFrame({
        'Value': importance_values,
        'Feature': features.columns
    })

    # Kümülatif yüzde hesapla (sadece mutlak değer ve yüzde modunda)
    if show_percentage and use_abs:
        feature_imp_sorted = feature_imp.sort_values(by="Value", ascending=False)
        feature_imp_sorted['Cumulative_%'] = feature_imp_sorted['Value'].cumsum()

        # %90'a ulaşan özellik sayısını bul
        features_90 = len(feature_imp_sorted[feature_imp_sorted['Cumulative_%'] <= 90])
        print(f"İlk {features_90} özellik modelin %90'ını temsil ediyor.")
        print(f"Top 10 özelliğin kümülatif katkısı: %{feature_imp_sorted.head(10)['Cumulative_%'].iloc[-1]:.1f}")

    # Görselleştirme
    plt.figure(figsize=(10, 10))
    sns.set(font_scale=1)

    plot_data = feature_imp.sort_values(by="Value", ascending=False)[0:num]

    sns.barplot(
        x="Value",
        y="Feature",
        data=plot_data
    )
    plt.title(f"{title} ({target})" )
    plt.xlabel(x_label)
    plt.tight_layout()
    plt.show()

    if save:
        filename = 'logistic_importances_pct.png' if show_percentage else 'logistic_importances.png'
        plt.savefig(filename)

    return feature_imp.sort_values(by="Value", ascending=False)

plot_importance(model, X, num=7, show_percentage=True)

plot_importance(model, X, num=7, use_abs=False)

def get_top_features_90_percent(model, features):
    """
    Modelin %90'ını temsil eden özellikleri bulur

    Returns:
    - DataFrame: Özellikler ve kümülatif yüzdeleri
    - int: %90'a ulaşmak için gereken özellik sayısı
    """

    # Katsayıları al
    if len(model.coef_.shape) > 1:
        coefficients = model.coef_[0]
    else:
        coefficients = model.coef_

    # Yüzdelik katkı hesapla
    abs_coefficients = np.abs(coefficients)
    total_importance = np.sum(abs_coefficients)
    percentages = (abs_coefficients / total_importance) * 100

    # DataFrame oluştur
    feature_imp = pd.DataFrame({
        'Feature': features.columns,
        'Importance_%': percentages,
        'Abs_Coefficient': abs_coefficients
    }).sort_values(by='Importance_%', ascending=False)

    # Kümülatif yüzde
    feature_imp['Cumulative_%'] = feature_imp['Importance_%'].cumsum()

    # %90'a ulaşan özellik sayısı
    features_90 = len(feature_imp[feature_imp['Cumulative_%'] <= 90])

    return feature_imp, features_90

#  %90 analizi için ayrı fonksiyon
top_features, count_90 = get_top_features_90_percent(model, X)
print(f"İlk {count_90} özellik modelin %90'ını açıklıyor")
print(top_features.head(count_90))

"""# y_proba"""

dff['rsi_40'].describe()